{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHc0rCxs2jPqzO0THdvtxx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrishnaPothula/PyDub-and-Whisper-Audio-Processing-and-NLP/blob/main/Segmenting_and_Transcribing_Audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydub"
      ],
      "metadata": {
        "id": "P-lgQ6UDHxcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "id": "43nHlecaHxXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install json"
      ],
      "metadata": {
        "id": "YqDOVb8IHxSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "from pydub import AudioSegment\n",
        "from whisper import Whisper\n",
        "import json"
      ],
      "metadata": {
        "id": "NLVioYF4Hf2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the audio file\n",
        "audio = AudioSegment.from_file(\"Test.mp3\")\n",
        "\n",
        "whisper = Whisper(dims=256)  # Adjust the dims parameter according to your model's requirements\n",
        "\n"
      ],
      "metadata": {
        "id": "tjmzQzkbHlRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to detect silence in the audio\n",
        "def detect_silence(audio, min_silence_len=1000, silence_thresh=-16):\n",
        "    start = 0\n",
        "    end = 0\n",
        "    detected = []\n",
        "    audio_len = len(audio)\n",
        "    while start < audio_len:\n",
        "        silence_start = audio[start:end].rfind(silence_thresh, 0, end-start)\n",
        "        if silence_start == -1:\n",
        "            break\n",
        "        else:\n",
        "            start += silence_start\n",
        "            end = start + min_silence_len\n",
        "            if end > audio_len:\n",
        "                end = audio_len\n",
        "        silence_end = audio[start:end].find(silence_thresh, 0, end-start)\n",
        "        if silence_end == -1:\n",
        "            detected.append((start, end))\n",
        "            break\n",
        "        else:\n",
        "            end = start + silence_end\n",
        "            detected.append((start, end))\n",
        "            start = end + 1\n",
        "    return detected\n",
        "\n"
      ],
      "metadata": {
        "id": "trDaAOsCHnaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to segment the audio by speaker\n",
        "def segment_audio(audio, silences):\n",
        "    segments = []\n",
        "    prev_end = 0\n",
        "    speaker = \"caller\"\n",
        "    for start, end in silences:\n",
        "        segment = audio[prev_end:start]\n",
        "        segments.append((segment, speaker))\n",
        "        speaker = \"callee\" if speaker == \"caller\" else \"caller\"\n",
        "        prev_end = end\n",
        "    if prev_end < len(audio):\n",
        "        segment = audio[prev_end:]\n",
        "        segments.append((segment, speaker))\n",
        "    return segments\n",
        "\n"
      ],
      "metadata": {
        "id": "d2RAvXfHHpk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to transcribe the audio segments using Whisper\n",
        "def transcribe_segments(segments):\n",
        "    transcriptions = []\n",
        "    for segment, speaker in segments:\n",
        "        text = whisper.transcribe(segment)\n",
        "        transcriptions.append((text, speaker))\n",
        "    return transcriptions\n",
        "\n"
      ],
      "metadata": {
        "id": "T1tS9RIRHrN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create a JSON file from the transcribed segments\n",
        "def create_json_file(transcriptions, filename):\n",
        "    data = {}\n",
        "    data[\"messages\"] = []\n",
        "    for text, speaker in transcriptions:\n",
        "        message = {}\n",
        "        message[\"text\"] = text.strip()\n",
        "        message[\"speaker\"] = speaker.capitalize()\n",
        "        data[\"messages\"].append(message)\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n"
      ],
      "metadata": {
        "id": "lDcXbYocHsQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the functions to complete the task\n",
        "silences = detect_silence(audio)\n",
        "segments = segment_audio(audio, silences)\n",
        "transcriptions = transcribe_segments(segments)\n",
        "create_json_file(transcriptions, \"conversation.json\")\n",
        "\n",
        "# Print a message to indicate the task is done\n",
        "print(\"The conversation has been segmented and transcribed successfully. The JSON file has been created.\")\n"
      ],
      "metadata": {
        "id": "3RMajclOHtUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}